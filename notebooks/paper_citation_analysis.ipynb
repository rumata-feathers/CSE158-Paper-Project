{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849ca924",
   "metadata": {},
   "source": [
    "# Paper Citation Prediction and Recommendation Models\n",
    "\n",
    "This notebook implements comprehensive citation prediction and paper recommendation models using the OpenAlex dataset. We'll build baseline and advanced models to predict citation relationships and recommend relevant papers to researchers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63a49e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f0e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve, auc,\n",
    "                             confusion_matrix, classification_report)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.sparse import csr_matrix\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0072cc",
   "metadata": {},
   "source": [
    "## 2. Synthetic Dataset Creation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic paper dataset\n",
    "def create_synthetic_papers(n_papers=500, n_authors=200, n_venues=50, seed=42):\n",
    "    \"\"\"\n",
    "    Create synthetic academic papers dataset with metadata.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create paper metadata\n",
    "    papers = []\n",
    "    venues = [f\"Venue_{i}\" for i in range(n_venues)]\n",
    "    authors_list = [f\"Author_{i}\" for i in range(n_authors)]\n",
    "    \n",
    "    for paper_id in range(n_papers):\n",
    "        paper = {\n",
    "            'paper_id': paper_id,\n",
    "            'title': f'Paper_{paper_id}',\n",
    "            'authors': list(np.random.choice(authors_list, size=np.random.randint(1, 5))),\n",
    "            'venue': np.random.choice(venues),\n",
    "            'year': np.random.randint(2015, 2024),\n",
    "            'citations_count': np.random.exponential(scale=10),\n",
    "            'abstract_length': np.random.randint(100, 1000),\n",
    "            'references_count': np.random.randint(20, 100),\n",
    "        }\n",
    "        papers.append(paper)\n",
    "    \n",
    "    papers_df = pd.DataFrame(papers)\n",
    "    return papers_df\n",
    "\n",
    "# Create citation links with realistic patterns\n",
    "def create_citation_network(papers_df, sparsity=0.95, seed=42):\n",
    "    \"\"\"\n",
    "    Create citation edges with patterns:\n",
    "    - Papers from same venue are more likely to cite each other\n",
    "    - Recent papers cite older papers\n",
    "    - Papers by same authors cite each other\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    citation_edges = []\n",
    "    n_papers = len(papers_df)\n",
    "    \n",
    "    for citing_idx in range(n_papers):\n",
    "        citing_paper = papers_df.iloc[citing_idx]\n",
    "        \n",
    "        # Potential papers that can be cited (published before this one)\n",
    "        potential_cited = papers_df[papers_df['year'] < citing_paper['year']].index.tolist()\n",
    "        \n",
    "        if len(potential_cited) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Probability of citation influenced by multiple factors\n",
    "        probabilities = []\n",
    "        for cited_idx in potential_cited:\n",
    "            cited_paper = papers_df.iloc[cited_idx]\n",
    "            \n",
    "            # Base probability\n",
    "            prob = 0.02\n",
    "            \n",
    "            # Author overlap boost\n",
    "            author_overlap = len(set(citing_paper['authors']) & set(cited_paper['authors']))\n",
    "            prob += author_overlap * 0.1\n",
    "            \n",
    "            # Venue similarity boost\n",
    "            if citing_paper['venue'] == cited_paper['venue']:\n",
    "                prob += 0.05\n",
    "            \n",
    "            # Citation count boost (popular papers cited more)\n",
    "            prob += min(0.1, cited_paper['citations_count'] / 100)\n",
    "            \n",
    "            probabilities.append(min(prob, 0.3))  # Cap at 0.3\n",
    "        \n",
    "        # Sample citations based on probabilities\n",
    "        probabilities = np.array(probabilities)\n",
    "        citations = np.random.binomial(1, probabilities)\n",
    "        \n",
    "        for i, cited_idx in enumerate(potential_cited):\n",
    "            if citations[i] == 1:\n",
    "                citation_edges.append({\n",
    "                    'citing_paper_id': citing_idx,\n",
    "                    'cited_paper_id': cited_idx,\n",
    "                    'label': 1\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(citation_edges)\n",
    "\n",
    "# Generate datasets\n",
    "papers_df = create_synthetic_papers(n_papers=500, n_authors=150, n_venues=40)\n",
    "citations_df = create_citation_network(papers_df)\n",
    "\n",
    "print(\"Papers Dataset Shape:\", papers_df.shape)\n",
    "print(\"\\nCitations Dataset Shape:\", citations_df.shape)\n",
    "print(\"\\nPapers Sample:\")\n",
    "print(papers_df.head())\n",
    "print(\"\\nCitations Sample:\")\n",
    "print(citations_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cbea8",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of citation patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Citation count distribution\n",
    "axes[0, 0].hist(papers_df['citations_count'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Citation Counts')\n",
    "axes[0, 0].set_xlabel('Number of Citations')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Papers by year\n",
    "year_counts = papers_df['year'].value_counts().sort_index()\n",
    "axes[0, 1].bar(year_counts.index, year_counts.values, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Number of Papers by Year')\n",
    "axes[0, 1].set_xlabel('Year')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Citations by venue (top 10)\n",
    "venue_citations = papers_df.groupby('venue')['citations_count'].mean().nlargest(10)\n",
    "axes[1, 0].barh(range(len(venue_citations)), venue_citations.values, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_yticks(range(len(venue_citations)))\n",
    "axes[1, 0].set_yticklabels(venue_citations.index)\n",
    "axes[1, 0].set_title('Average Citations by Top 10 Venues')\n",
    "axes[1, 0].set_xlabel('Average Citations')\n",
    "\n",
    "# Citation network statistics\n",
    "print(\"\\n=== Citation Network Statistics ===\")\n",
    "print(f\"Total papers: {len(papers_df)}\")\n",
    "print(f\"Total citation pairs: {len(citations_df)}\")\n",
    "print(f\"Citation sparsity: {1 - len(citations_df) / (len(papers_df) * len(papers_df)):.4f}\")\n",
    "print(f\"Average citations per paper: {len(citations_df) / len(papers_df):.2f}\")\n",
    "print(f\"Citation density: {len(citations_df) / (len(papers_df) * (len(papers_df) - 1) / 2):.4f}\")\n",
    "\n",
    "# Network visualization\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(papers_df['paper_id'])\n",
    "for _, row in citations_df.iterrows():\n",
    "    G.add_edge(row['citing_paper_id'], row['cited_paper_id'])\n",
    "\n",
    "in_degree = dict(G.in_degree())\n",
    "out_degree = dict(G.out_degree())\n",
    "axes[1, 1].scatter([in_degree[node] for node in G.nodes()], \n",
    "                   [out_degree[node] for node in G.nodes()], \n",
    "                   alpha=0.6, s=50)\n",
    "axes[1, 1].set_title('In-Degree vs Out-Degree')\n",
    "axes[1, 1].set_xlabel('In-Degree (Cited By)')\n",
    "axes[1, 1].set_ylabel('Out-Degree (Cites)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNetwork density: {nx.density(G):.4f}\")\n",
    "print(f\"Number of weakly connected components: {nx.number_weakly_connected_components(G)}\")\n",
    "print(f\"Average clustering coefficient: {nx.average_clustering(G.to_undirected()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c596a1f",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering for Citation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064dbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(citing_idx, cited_idx, papers_df, citations_df, G):\n",
    "    \"\"\"\n",
    "    Extract features for a citation pair.\n",
    "    \"\"\"\n",
    "    citing_paper = papers_df.iloc[citing_idx]\n",
    "    cited_paper = papers_df.iloc[cited_idx]\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # 1. Temporal Features\n",
    "    time_diff = citing_paper['year'] - cited_paper['year']\n",
    "    features['time_diff'] = time_diff\n",
    "    features['citing_recency'] = 2024 - citing_paper['year']\n",
    "    features['cited_recency'] = 2024 - cited_paper['year']\n",
    "    \n",
    "    # 2. Author Features\n",
    "    citing_authors = set(citing_paper['authors'])\n",
    "    cited_authors = set(cited_paper['authors'])\n",
    "    author_overlap = len(citing_authors & cited_authors)\n",
    "    features['author_overlap'] = author_overlap\n",
    "    features['author_overlap_jaccard'] = author_overlap / len(citing_authors | cited_authors) if len(citing_authors | cited_authors) > 0 else 0\n",
    "    \n",
    "    # 3. Venue Features\n",
    "    features['same_venue'] = 1 if citing_paper['venue'] == cited_paper['venue'] else 0\n",
    "    \n",
    "    # 4. Citation Count Features\n",
    "    features['citing_citation_count'] = citing_paper['citations_count']\n",
    "    features['cited_citation_count'] = cited_paper['citations_count']\n",
    "    features['cite_count_diff'] = citing_paper['citations_count'] - cited_paper['citations_count']\n",
    "    \n",
    "    # 5. References Count Features\n",
    "    features['citing_references'] = citing_paper['references_count']\n",
    "    features['cited_references'] = cited_paper['references_count']\n",
    "    \n",
    "    # 6. Abstract/Title Similarity (based on length as proxy)\n",
    "    features['abstract_diff'] = abs(citing_paper['abstract_length'] - cited_paper['abstract_length'])\n",
    "    features['title_similarity'] = 1.0 if citing_paper['title'] == cited_paper['title'] else 0.0\n",
    "    \n",
    "    # 7. Graph Features\n",
    "    try:\n",
    "        features['citing_in_degree'] = G.in_degree(citing_idx)\n",
    "        features['citing_out_degree'] = G.out_degree(citing_idx)\n",
    "        features['cited_in_degree'] = G.in_degree(cited_idx)\n",
    "        features['cited_out_degree'] = G.out_degree(cited_idx)\n",
    "        features['common_citations'] = len(list(G.predecessors(citing_idx)) & set(G.predecessors(cited_idx)))\n",
    "    except:\n",
    "        features['citing_in_degree'] = 0\n",
    "        features['citing_out_degree'] = 0\n",
    "        features['cited_in_degree'] = 0\n",
    "        features['cited_out_degree'] = 0\n",
    "        features['common_citations'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for positive examples (existing citations)\n",
    "positive_features_list = []\n",
    "for _, row in citations_df.iterrows():\n",
    "    features = extract_features(row['citing_paper_id'], row['cited_paper_id'], papers_df, citations_df, G)\n",
    "    features['label'] = 1\n",
    "    positive_features_list.append(features)\n",
    "\n",
    "# Create negative examples (pairs that don't cite each other)\n",
    "existing_citations = set((row['citing_paper_id'], row['cited_paper_id']) for _, row in citations_df.iterrows())\n",
    "negative_features_list = []\n",
    "n_negative = len(positive_features_list)  # Balance the dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "count = 0\n",
    "attempts = 0\n",
    "max_attempts = 10000\n",
    "\n",
    "while count < n_negative and attempts < max_attempts:\n",
    "    citing_idx = np.random.randint(0, len(papers_df))\n",
    "    cited_idx = np.random.randint(0, len(papers_df))\n",
    "    \n",
    "    # Ensure valid pair\n",
    "    if citing_idx != cited_idx and (citing_idx, cited_idx) not in existing_citations:\n",
    "        # Only include if temporal order is valid (citing published after cited)\n",
    "        if papers_df.iloc[citing_idx]['year'] >= papers_df.iloc[cited_idx]['year']:\n",
    "            features = extract_features(citing_idx, cited_idx, papers_df, citations_df, G)\n",
    "            features['label'] = 0\n",
    "            negative_features_list.append(features)\n",
    "            count += 1\n",
    "    \n",
    "    attempts += 1\n",
    "\n",
    "# Combine and create dataset\n",
    "all_features_list = positive_features_list + negative_features_list\n",
    "features_df = pd.DataFrame(all_features_list)\n",
    "\n",
    "print(f\"Total features extracted: {len(features_df)}\")\n",
    "print(f\"Positive examples: {(features_df['label'] == 1).sum()}\")\n",
    "print(f\"Negative examples: {(features_df['label'] == 0).sum()}\")\n",
    "print(f\"\\nFeature columns: {features_df.columns.tolist()}\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(features_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672e411",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing and Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ddb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = features_df.drop(['label'], axis=1)\n",
    "y = features_df['label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# ===== BASELINE MODELS =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Random Baseline\n",
    "random_preds = np.random.binomial(1, y_train.mean(), size=len(y_test))\n",
    "print(\"\\n1. RANDOM BASELINE\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, random_preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, random_preds, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, random_preds, zero_division=0):.4f}\")\n",
    "\n",
    "# 2. Majority Class Baseline\n",
    "majority_preds = np.ones(len(y_test)) * (1 if y_train.mean() > 0.5 else 0)\n",
    "print(\"\\n2. MAJORITY CLASS BASELINE\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, majority_preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, majority_preds, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, majority_preds, zero_division=0):.4f}\")\n",
    "\n",
    "# 3. Popularity-based Baseline (cite high-citation papers)\n",
    "def popularity_baseline(X_val, X_test, y_test, feature_name='cited_citation_count'):\n",
    "    median_val = X_val[feature_name].median()\n",
    "    preds_val = (X_val[feature_name] > median_val).astype(int)\n",
    "    preds_test = (X_test[feature_name] > median_val).astype(int)\n",
    "    \n",
    "    print(\"\\n3. POPULARITY-BASED BASELINE\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, preds_test):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, preds_test, zero_division=0):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, preds_test, zero_division=0):.4f}\")\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, preds_test):.4f}\")\n",
    "    \n",
    "    return preds_test\n",
    "\n",
    "popularity_preds = popularity_baseline(X_val, X_test, y_test)\n",
    "\n",
    "# 4. Author Overlap Baseline\n",
    "def author_overlap_baseline(X_val, X_test, y_test):\n",
    "    median_val = X_val['author_overlap'].median()\n",
    "    preds_val = (X_val['author_overlap'] > median_val).astype(int)\n",
    "    preds_test = (X_test['author_overlap'] > median_val).astype(int)\n",
    "    \n",
    "    print(\"\\n4. AUTHOR OVERLAP BASELINE\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, preds_test):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, preds_test, zero_division=0):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, preds_test, zero_division=0):.4f}\")\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, preds_test):.4f}\")\n",
    "    \n",
    "    return preds_test\n",
    "\n",
    "author_preds = author_overlap_baseline(X_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce334d",
   "metadata": {},
   "source": [
    "## 6. Advanced Citation Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train advanced models\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADVANCED CITATION PREDICTION MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print(\"\\n1. LOGISTIC REGRESSION\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "models['Logistic Regression'] = lr_model\n",
    "predictions['Logistic Regression'] = lr_pred\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, lr_pred):.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, lr_pred_proba):.4f}\")\n",
    "\n",
    "# Feature importance for LR\n",
    "lr_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "print(\"\\nTop 10 Features (Logistic Regression):\")\n",
    "print(lr_importance.head(10))\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\n2. RANDOM FOREST\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "models['Random Forest'] = rf_model\n",
    "predictions['Random Forest'] = rf_pred\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, rf_pred_proba):.4f}\")\n",
    "\n",
    "# Feature importance for RF\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 10 Features (Random Forest):\")\n",
    "print(rf_importance.head(10))\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "print(\"\\n3. GRADIENT BOOSTING\")\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "gb_pred_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "models['Gradient Boosting'] = gb_model\n",
    "predictions['Gradient Boosting'] = gb_pred\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, gb_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, gb_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, gb_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, gb_pred):.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test, gb_pred_proba):.4f}\")\n",
    "\n",
    "# Feature importance for GB\n",
    "gb_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 10 Features (Gradient Boosting):\")\n",
    "print(gb_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
